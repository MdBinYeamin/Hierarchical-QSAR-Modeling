{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Models\n",
    "\n",
    "## Endponits:\n",
    " - (1) EPA category (class 1-4), \n",
    " - (2) GHS category (class 1-5), \n",
    " - (3) LD50 (mmol/kg); \n",
    " - (4) toxic (LD50 < 2,000 mg/kg == 1)\n",
    " - (5) very toxic (LD50 < 50 mg/kg == 1)\n",
    " \n",
    " \n",
    "## Algorithms:\n",
    " - Random Forest\n",
    " - SVM & SVR\n",
    " - XGBOOST\n",
    " - kNN\n",
    " \n",
    "All model were tuned with 5-fold cross-validation.\n",
    "\n",
    "## Endpoint 1: Toxic\n",
    " - kNN: {'n_neighbors': 71, 'p': 1, 'weights': 'distance'}; Best score: 0.880\n",
    " - SVM: {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}; Best score: 0.883\n",
    " - RF: {'n_estimators': 1500, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'log2', 'max_depth': 35, 'bootstrap': False}; Best score: 0.882\n",
    " - xgb: {'subsample': 0.6, 'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.01, 'gamma': 0, 'colsample_bytree': 0.5}; Best score: 0.883\n",
    " \n",
    "## Endpoint 2: LD50\n",
    " - RF: {'n_estimators': 1500, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': False}; Best score: 0.304\n",
    " - xgb: {'subsample': 0.6, 'n_estimators': 500, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 1, 'colsample_bytree': 0.6}; Best score: 0.304\n",
    " - svm: {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}; Best score: 0.304\n",
    " - kNN: {'n_neighbors': 45, 'p': 2, 'weights': 'distance'}; Best score: 0.315\n",
    " \n",
    "## Endpoint 3: Multiclass\n",
    " - RF: {'n_estimators': 500, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}; Best score: 0.641\n",
    " - xgb: {'subsample': 0.6, 'n_estimators': 1500, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.01, 'gamma': 5, 'colsample_bytree': 0.7}; Best score: 0.640\n",
    " - svm: {'C': 0.1, 'kernel': 'linear'} Best score: 0.636\n",
    " - knn: {'n_neighbors': 35, 'p': 1, 'weights': 'distance'}; Best score: 0.631"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import * \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import itertools\n",
    "from pprint import pprint\n",
    "import joblib\n",
    "\n",
    "import statistics\n",
    "\n",
    "# Models\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from sklearn.model_selection import KFold, cross_validate, GridSearchCV, cross_val_score, RandomizedSearchCV \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#regression matrics\n",
    "from sklearn.metrics import mean_absolute_error , mean_squared_error, r2_score\n",
    "\n",
    "#classification metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score, f1_score, matthews_corrcoef\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection._split import check_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8221, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.read_csv('../data/train_test_sets/train_labels.csv', index_col = 'CASRN')\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8221, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Hfeatures = pd.read_csv('../data/Hmodel_features_combined/train_Hfeatures.csv', index_col = 'CASRN')\n",
    "train_Hfeatures.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint 1: Toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.805 std: 0.015\n",
      "Balance Accuracy: 0.799 std: 0.014\n",
      "matthews_corrcoef: 0.601 std: 0.029\n",
      "f1_score: 0.804 std: 0.015\n",
      "AUROC: 0.799 std: 0.014\n",
      "CPU times: user 2min 59s, sys: 12.2 s, total: 3min 11s\n",
      "Wall time: 5min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "endpoint = 'Toxic'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'RF'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "encoder_toxic = joblib.load('../data/label_encoders/encoder_toxic.joblib')\n",
    "\n",
    "# model\n",
    "rf_clf = RandomForestClassifier(random_state =42, n_jobs=6,\n",
    "                              n_estimators = 1500, min_samples_split = 5, min_samples_leaf=6,\n",
    "                              max_features = 'log2', max_depth=35, bootstrap= False)\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'toxic', encoder = encoder_toxic)\n",
    "\n",
    "# results\n",
    "BCM_mf,  BCM_oof, BCM_base_model, cv_score  = Classification_meta_features(rf_clf, a, c, b, d, e,cv=10,n_jobs=1, \n",
    "                                                      col_names = [f'{name}-0', f'{name}-1'])\n",
    "# report the results\n",
    "report_clf_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "# BCM_mf.to_csv(f'../data/Hmodel_features/{name}.csv') # no need for this \n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', BCM_oof)\n",
    "joblib.dump(BCM_base_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.799 std: 0.015\n",
      "Balance Accuracy: 0.792 std: 0.015\n",
      "matthews_corrcoef: 0.588 std: 0.03\n",
      "f1_score: 0.798 std: 0.015\n",
      "AUROC: 0.792 std: 0.015\n",
      "CPU times: user 25 s, sys: 308 ms, total: 25.3 s\n",
      "Wall time: 3min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "endpoint = 'Toxic'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'SVM'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "encoder_toxic = joblib.load('../data/label_encoders/encoder_toxic.joblib')\n",
    "\n",
    "# model\n",
    "clf = SVC(random_state=42, probability=True,\n",
    "          C = 10, gamma = 0.001, kernel = 'rbf')\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'toxic', encoder = encoder_toxic)\n",
    "\n",
    "# results\n",
    "BCM_mf,  BCM_oof, BCM_model, cv_score  = Classification_meta_features(clf, a, c, b, d, e,cv=10,n_jobs=6, \n",
    "                                                      col_names = [f'{name}-0', f'{name}-1'])\n",
    "# report the results\n",
    "report_clf_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "# BCM_mf.to_csv(f'../data/Hmodel_features/{name}.csv') # no need for this \n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', BCM_oof)\n",
    "joblib.dump(BCM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.802 std: 0.011\n",
      "Balance Accuracy: 0.795 std: 0.01\n",
      "matthews_corrcoef: 0.594 std: 0.021\n",
      "f1_score: 0.801 std: 0.011\n",
      "AUROC: 0.795 std: 0.01\n",
      "CPU times: user 4min 56s, sys: 375 ms, total: 4min 56s\n",
      "Wall time: 50.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "endpoint = 'Toxic'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'xgboost'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "encoder_toxic = joblib.load('../data/label_encoders/encoder_toxic.joblib')\n",
    "\n",
    "# model\n",
    "clf = XGBClassifier(random_state =123, n_jobs=6,\n",
    "                    subsample = 0.6, n_estimators = 500, min_child_weight=1,\n",
    "                    max_depth = 3, learning_rate=0.01, gamma= 0,\n",
    "                    colsample_bytree = 0.5)\n",
    "\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'toxic', encoder = encoder_toxic)\n",
    "\n",
    "# results\n",
    "BCM_mf,  BCM_oof, BCM_model, cv_score  = Classification_meta_features(clf, a, c, b, d, e,cv=10,n_jobs=1, \n",
    "                                                      col_names = [f'{name}-0', f'{name}-1'])\n",
    "# report the results\n",
    "report_clf_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "# BCM_mf.to_csv(f'../data/Hmodel_features/{name}.csv') # no need for this \n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', BCM_oof)\n",
    "joblib.dump(BCM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.796 std: 0.017\n",
      "Balance Accuracy: 0.79 std: 0.017\n",
      "matthews_corrcoef: 0.584 std: 0.034\n",
      "f1_score: 0.796 std: 0.017\n",
      "AUROC: 0.79 std: 0.017\n",
      "CPU times: user 140 ms, sys: 52.4 ms, total: 192 ms\n",
      "Wall time: 18.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "endpoint = 'Toxic'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'knn'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "encoder_toxic = joblib.load('../data/label_encoders/encoder_toxic.joblib')\n",
    "\n",
    "# model\n",
    "clf = KNeighborsClassifier(n_neighbors = 71, weights = 'distance')\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'toxic', encoder = encoder_toxic)\n",
    "\n",
    "# results\n",
    "BCM_mf,  BCM_oof, BCM_model, cv_score  = Classification_meta_features(clf, a, c, b, d, e,cv=10,n_jobs=6, \n",
    "                                                      col_names = [f'{name}-0', f'{name}-1'])\n",
    "# report the results\n",
    "report_clf_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "# BCM_mf.to_csv(f'../data/Hmodel_features/{name}.csv') # no need for this \n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', BCM_oof)\n",
    "joblib.dump(BCM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint 2: EPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.659 std: 0.016\n",
      "Balance Accuracy: 0.587 std: 0.015\n",
      "matthews_corrcoef: 0.458 std: 0.023\n",
      "f1_score: 0.648 std: 0.017\n",
      "AUROC: 0.707 std: 0.012\n",
      "CPU times: user 1min 27s, sys: 4.99 s, total: 1min 32s\n",
      "Wall time: 3min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "endpoint = 'EPA'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'RF'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "encoder_epa = joblib.load('../data/label_encoders/encoder_epa.joblib')\n",
    "\n",
    "# model\n",
    "clf = RandomForestClassifier(random_state =42, n_jobs=6,\n",
    "                              n_estimators = 500, min_samples_split = 10, min_samples_leaf=6,\n",
    "                              max_features = 'sqrt', max_depth=None, bootstrap= False)\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'EPA_category', encoder = encoder_epa)\n",
    "\n",
    "# results\n",
    "MCM_mf,  MCM_oof, MCM_model, cv_score  = Classification_meta_features(clf, a, c, b, d, e,cv=10,n_jobs=1, \n",
    "                                                      col_names = [f'{name}-1', f'{name}-2', f'{name}-3', f'{name}-4'])\n",
    "# report the results\n",
    "report_clf_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', MCM_oof)\n",
    "joblib.dump(MCM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.658 std: 0.015\n",
      "Balance Accuracy: 0.588 std: 0.012\n",
      "matthews_corrcoef: 0.456 std: 0.023\n",
      "f1_score: 0.647 std: 0.017\n",
      "AUROC: 0.708 std: 0.013\n",
      "CPU times: user 3h 33min 48s, sys: 16.1 s, total: 3h 34min 4s\n",
      "Wall time: 36min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "endpoint = 'EPA'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'xgboost'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "encoder_epa = joblib.load('../data/label_encoders/encoder_epa.joblib')\n",
    "\n",
    "# model\n",
    "clf = XGBClassifier(random_state =123, n_jobs=6,\n",
    "                    subsample = 0.6, n_estimators = 1500, min_child_weight=3,\n",
    "                    max_depth = 10, learning_rate=0.01, gamma= 5,\n",
    "                    colsample_bytree = 0.7)\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'EPA_category', encoder = encoder_epa)\n",
    "\n",
    "# results\n",
    "MCM_mf,  MCM_oof, MCM_model, cv_score  = Classification_meta_features(clf, a, c, b, d, e,cv=10,n_jobs=1, \n",
    "                                                      col_names = [f'{name}-1', f'{name}-2', f'{name}-3', f'{name}-4'])\n",
    "# report the results\n",
    "report_clf_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', MCM_oof)\n",
    "joblib.dump(MCM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.654 std: 0.018\n",
      "Balance Accuracy: 0.576 std: 0.013\n",
      "matthews_corrcoef: 0.447 std: 0.023\n",
      "f1_score: 0.64 std: 0.02\n",
      "AUROC: 0.7 std: 0.014\n",
      "CPU times: user 239 ms, sys: 172 ms, total: 411 ms\n",
      "Wall time: 24.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "endpoint = 'EPA'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'knn'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "encoder_epa = joblib.load('../data/label_encoders/encoder_epa.joblib')\n",
    "\n",
    "# model\n",
    "clf = KNeighborsClassifier(n_neighbors = 35, weights = 'distance', p=1)\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'EPA_category', encoder = encoder_epa)\n",
    "\n",
    "# results\n",
    "MCM_mf,  MCM_oof, MCM_model, cv_score  = Classification_meta_features(clf, a, c, b, d, e,cv=10,n_jobs=6, \n",
    "                                                      col_names = [f'{name}-1', f'{name}-2', f'{name}-3', f'{name}-4'])\n",
    "# report the results\n",
    "report_clf_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', MCM_oof)\n",
    "joblib.dump(MCM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinhao/.local/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.655 std: 0.015\n",
      "Balance Accuracy: 0.569 std: 0.013\n",
      "matthews_corrcoef: 0.448 std: 0.018\n",
      "f1_score: 0.639 std: 0.017\n",
      "AUROC: 0.699 std: 0.01\n",
      "CPU times: user 25.4 s, sys: 228 ms, total: 25.6 s\n",
      "Wall time: 3min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "endpoint = 'EPA'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'SVM'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "encoder_epa = joblib.load('../data/label_encoders/encoder_epa.joblib')\n",
    "\n",
    "# model\n",
    "clf = SVC(random_state=42, probability=True,\n",
    "          C = 0.1, kernel = 'linear')\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'EPA_category', encoder = encoder_epa)\n",
    "\n",
    "# results\n",
    "MCM_mf,  MCM_oof, MCM_model, cv_score  = Classification_meta_features(clf, a, c, b, d, e,cv=10,n_jobs=6, \n",
    "                                                      col_names = [f'{name}-1', f'{name}-2', f'{name}-3', f'{name}-4'])\n",
    "# report the results\n",
    "report_clf_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', MCM_oof)\n",
    "joblib.dump(MCM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint 3: LD50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.549 std: 0.025\n",
      "R2: 0.631 std: 0.028\n",
      "MAE: 0.396 std: 0.019\n",
      "MSE: 0.301 std: 0.027\n",
      "CPU times: user 2min 55s, sys: 6.4 s, total: 3min 1s\n",
      "Wall time: 6min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "endpoint = 'LD50'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'RF'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "# model\n",
    "rf_reg = RandomForestRegressor(random_state =42, n_jobs=6,\n",
    "                              n_estimators = 1500, min_samples_split = 2, min_samples_leaf=4,\n",
    "                              max_features = 'sqrt', max_depth=20, bootstrap= False)\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'logLD50_mmolkg')\n",
    "\n",
    "# results\n",
    "RM_mf, RM_oof, RM_model, cv_score = Regression_meta_features(rf_reg, a, c, b, \n",
    "                                                       d, e,cv=10, n_jobs = 1, col_names = [f'{name}'])\n",
    "# report the results\n",
    "report_cv_reg_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', RM_oof)\n",
    "joblib.dump(RM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.55 std: 0.024\n",
      "R2: 0.628 std: 0.027\n",
      "MAE: 0.398 std: 0.018\n",
      "MSE: 0.303 std: 0.027\n",
      "CPU times: user 9min 14s, sys: 982 ms, total: 9min 15s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "endpoint = 'LD50'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'xgboost'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "# model\n",
    "reg = XGBRegressor(random_state =123, n_jobs=6, objective ='reg:squarederror',\n",
    "                    subsample = 0.6, n_estimators = 500, min_child_weight=3,\n",
    "                    max_depth = 6, learning_rate=0.01, gamma= 1,\n",
    "                    colsample_bytree = 0.6)\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'logLD50_mmolkg')\n",
    "\n",
    "# results\n",
    "RM_mf, RM_oof, RM_model, cv_score = Regression_meta_features(reg, a, c, b, \n",
    "                                                       d, e,cv=10, n_jobs = 1, col_names = [f'{name}'])\n",
    "# report the results\n",
    "report_cv_reg_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', RM_oof)\n",
    "joblib.dump(RM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.559 std: 0.024\n",
      "R2: 0.617 std: 0.028\n",
      "MAE: 0.405 std: 0.018\n",
      "MSE: 0.312 std: 0.027\n",
      "CPU times: user 1.54 s, sys: 176 ms, total: 1.72 s\n",
      "Wall time: 15.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "endpoint = 'LD50'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'knn'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "# model\n",
    "reg = KNeighborsRegressor(p = 2, n_neighbors = 45, weights = 'distance')\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'logLD50_mmolkg')\n",
    "\n",
    "# results\n",
    "RM_mf, RM_oof, RM_model, cv_score = Regression_meta_features(reg, a, c, b, \n",
    "                                                       d, e,cv=10, n_jobs = 6, col_names = [f'{name}'])\n",
    "# report the results\n",
    "report_cv_reg_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', RM_oof)\n",
    "joblib.dump(RM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.551 std: 0.024\n",
      "R2: 0.628 std: 0.026\n",
      "MAE: 0.395 std: 0.018\n",
      "MSE: 0.304 std: 0.026\n",
      "CPU times: user 5.29 s, sys: 64 ms, total: 5.35 s\n",
      "Wall time: 29.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "endpoint = 'LD50'\n",
    "descriptor = 'Hmodel'\n",
    "algorithm = 'SVM'\n",
    "name = f'{endpoint}_{algorithm}_{descriptor}'\n",
    "\n",
    "# model\n",
    "reg = SVR(C = 1, gamma = 0.01, kernel = 'rbf')\n",
    "\n",
    "#input\n",
    "a, b,c,d,e = prepare_input(train_labels, train_Hfeatures, target = 'logLD50_mmolkg')\n",
    "\n",
    "# results\n",
    "RM_mf, RM_oof, RM_model, cv_score = Regression_meta_features(reg, a, c, b, \n",
    "                                                       d, e,cv=10, n_jobs = 6, col_names = [f'{name}'])\n",
    "# report the results\n",
    "report_cv_reg_models(cv_score)\n",
    "\n",
    "# Save results\n",
    "np.save(f'../results/Hierarchical_models/{name}.npy', RM_oof)\n",
    "joblib.dump(RM_model, f'../models/Hierarchical_models/{name}.pkl')\n",
    "joblib.dump(cv_score, f'../results/Hierarchical_models/{name}_CVScore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the predictrions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2849, 100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Hfeatures = pd.read_csv('../data/Hmodel_features_combined/test_Hfeatures.csv', index_col = 'CASRN')\n",
    "test_Hfeatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic_RF_Hmodel: computing....\n",
      "Toxic_RF_Hmodel: saved\n",
      "Toxic_SVM_Hmodel: computing....\n",
      "Toxic_SVM_Hmodel: saved\n",
      "Toxic_knn_Hmodel: computing....\n",
      "Toxic_knn_Hmodel: saved\n",
      "Toxic_xgboost_Hmodel: computing....\n",
      "Toxic_xgboost_Hmodel: saved\n",
      "EPA_RF_Hmodel: computing....\n",
      "EPA_RF_Hmodel: saved\n",
      "EPA_SVM_Hmodel: computing....\n",
      "EPA_SVM_Hmodel: saved\n",
      "EPA_knn_Hmodel: computing....\n",
      "EPA_knn_Hmodel: saved\n",
      "EPA_xgboost_Hmodel: computing....\n",
      "EPA_xgboost_Hmodel: saved\n",
      "LD50_RF_Hmodel: computing....\n",
      "LD50_RF_Hmodel: saved\n",
      "LD50_SVM_Hmodel: computing....\n",
      "LD50_SVM_Hmodel: saved\n",
      "LD50_knn_Hmodel: computing....\n",
      "LD50_knn_Hmodel: saved\n",
      "LD50_xgboost_Hmodel: computing....\n",
      "LD50_xgboost_Hmodel: saved\n",
      "CPU times: user 18.9 s, sys: 560 ms, total: 19.4 s\n",
      "Wall time: 15.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "index = test_Hfeatures.index\n",
    "\n",
    "model_path = '../models/Hierarchical_models/'\n",
    "result_path = '../results/Hierarchical_testset_preds/'\n",
    "\n",
    "endpoints = ['Toxic', 'EPA', 'LD50']\n",
    "descriptors = ['Hmodel']\n",
    "algorithms = ['RF', 'SVM', 'knn', 'xgboost']\n",
    "\n",
    "feature = test_Hfeatures.values.astype('float32')\n",
    "\n",
    "for e in endpoints:\n",
    "    for d in descriptors:\n",
    "        for a in algorithms:\n",
    "            name = f'{e}_{a}_{d}'\n",
    "            print(f'{name}: computing....')\n",
    "            model = joblib.load(f'{model_path}{name}.pkl')\n",
    "            \n",
    "            if e == 'Toxic':\n",
    "                predictions = model.predict_proba(feature)\n",
    "                df = pd.DataFrame(predictions, columns=[f'{name}-0', f'{name}-1'],index = index)\n",
    "                df.to_csv(f'{result_path}{name}.csv')\n",
    "\n",
    "                print(f'{name}: saved')\n",
    "            if e == 'EPA':\n",
    "                predictions = model.predict_proba(feature)\n",
    "                df = pd.DataFrame(predictions, columns=[f'{name}-1', f'{name}-2', f'{name}-3', f'{name}-4'], index = index)\n",
    "                df.to_csv(f'{result_path}{name}.csv')\n",
    "\n",
    "                print(f'{name}: saved')\n",
    "            if e == 'LD50':\n",
    "                predictions = model.predict(feature)\n",
    "                df = pd.DataFrame(predictions, columns=[f'{name}'],index = index)\n",
    "                df.to_csv(f'{result_path}{name}.csv')\n",
    "                print(f'{name}: saved') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
